{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from textblob import TextBlob\n",
    "from textstat.textstat import textstat\n",
    "from langdetect import detect\n",
    "\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook', rc={'figure.figsize': (10, 6)}, font_scale=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resource_folder = 'contract_data/Contracts_Annotations/resource_contracts/'\n",
    "land_folder = 'contract_data/Contracts_Annotations/openland_contracts/'\n",
    "folders = [resource_folder,land_folder]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_labels = ['stabilization','royalties']\n",
    "n_folds = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Languages must be supported by NLTK Snowball Stemmer and stopwords\n",
    "languages = ['english','french','spanish','italian','portuguese','dutch','swedish']\n",
    "language_codes = pd.read_csv('http://data.okfn.org/data/core/language-codes/r/language-codes.csv')\n",
    "language_codes.columns = ['language_code','Language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotations: 20609\n"
     ]
    }
   ],
   "source": [
    "annotations = pd.DataFrame()\n",
    "for folder in folders:\n",
    "    xls_files = [f for f in os.listdir(folder) if f.lower().endswith('.xls')]\n",
    "    for xls in xls_files:\n",
    "        temp = pd.read_excel(folder + xls)\n",
    "        if len(temp) > 0:\n",
    "            temp['OCID'] = xls[:-4]\n",
    "            temp['Source'] = folder.split('/')[-2]\n",
    "            annotations = annotations.append(temp)\n",
    "print \"Number of annotations: \" + str(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.54% stabilization\n",
      "2.37% royalties\n"
     ]
    }
   ],
   "source": [
    "labels = {}\n",
    "for label in target_labels:\n",
    "    labels[label] = [1 if x.lower() == label.lower() else 0 for x in annotations['Category']]\n",
    "    print str(\"{0:.2f}%\".format(100*np.sum(labels[label]) / float(len(labels[label])))) + ' ' + label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Annotation Text</th>\n",
       "      <th>PDF Page Number</th>\n",
       "      <th>Article Reference</th>\n",
       "      <th>OCID</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project title</td>\n",
       "      <td>General</td>\n",
       "      <td>Production Sharing Contract between Sociedade ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Name of field, block, deposit or site</td>\n",
       "      <td>General</td>\n",
       "      <td>Block 20/11</td>\n",
       "      <td>1</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name of company executing document</td>\n",
       "      <td>General</td>\n",
       "      <td>CIE Angola Block 20 LTD (referred to as Cobalt...</td>\n",
       "      <td>3</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>State agency, national company or ministry exe...</td>\n",
       "      <td>General</td>\n",
       "      <td>Sociedade Nacional de Combustiveis de Angola, ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Type of contract</td>\n",
       "      <td>General</td>\n",
       "      <td>Production Sharing Contract</td>\n",
       "      <td>3</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Country</td>\n",
       "      <td>General</td>\n",
       "      <td>Angola</td>\n",
       "      <td>3</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Parent company or affiliates outside of country</td>\n",
       "      <td>General</td>\n",
       "      <td>Cobalt, Cayman Islands; BP Exploration Angola ...</td>\n",
       "      <td>3</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Resource(s)</td>\n",
       "      <td>General</td>\n",
       "      <td>Hydrocarbons</td>\n",
       "      <td>4</td>\n",
       "      <td>Preamble</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Date of issue of title/permit</td>\n",
       "      <td>General</td>\n",
       "      <td>40909</td>\n",
       "      <td>5</td>\n",
       "      <td>Art. 1.15</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Infrastructure</td>\n",
       "      <td>Operations</td>\n",
       "      <td>Contractor Group may construct and install pip...</td>\n",
       "      <td>5</td>\n",
       "      <td>Arts. 1.18, 19, 20.3, 29.3</td>\n",
       "      <td>ocds-591adf-0014595575</td>\n",
       "      <td>resource_contracts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Category       Topic  \\\n",
       "0                                      Project title     General   \n",
       "1              Name of field, block, deposit or site     General   \n",
       "2                 Name of company executing document     General   \n",
       "3  State agency, national company or ministry exe...     General   \n",
       "4                                   Type of contract     General   \n",
       "5                                            Country     General   \n",
       "6    Parent company or affiliates outside of country     General   \n",
       "7                                        Resource(s)     General   \n",
       "8                      Date of issue of title/permit     General   \n",
       "9                                     Infrastructure  Operations   \n",
       "\n",
       "                                     Annotation Text  PDF Page Number  \\\n",
       "0  Production Sharing Contract between Sociedade ...                1   \n",
       "1                                        Block 20/11                1   \n",
       "2  CIE Angola Block 20 LTD (referred to as Cobalt...                3   \n",
       "3  Sociedade Nacional de Combustiveis de Angola, ...                3   \n",
       "4                        Production Sharing Contract                3   \n",
       "5                                             Angola                3   \n",
       "6  Cobalt, Cayman Islands; BP Exploration Angola ...                3   \n",
       "7                                       Hydrocarbons                4   \n",
       "8                                              40909                5   \n",
       "9  Contractor Group may construct and install pip...                5   \n",
       "\n",
       "            Article Reference                    OCID              Source  \n",
       "0                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "1                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "2                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "3                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "4                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "5                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "6                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "7                    Preamble  ocds-591adf-0014595575  resource_contracts  \n",
       "8                   Art. 1.15  ocds-591adf-0014595575  resource_contracts  \n",
       "9  Arts. 1.18, 19, 20.3, 29.3  ocds-591adf-0014595575  resource_contracts  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "punctuation_re = r'[^\\w\\s#]'\n",
    "\n",
    "def punctuation_remove(text):\n",
    "    \"\"\"\n",
    "    Mutates and returns text where all punctuation besides hashtags,\n",
    "    are replaced\n",
    "    \"\"\"\n",
    "    new_text = nltk.regexp.re.sub(punctuation_re, ' ', text)\n",
    "    return new_text\n",
    "\n",
    "def perform_lowercase(text):\n",
    "    \"\"\"\n",
    "    Mutates and returns text where all characters are lowercased\n",
    "    \"\"\"\n",
    "    try:\n",
    "        new_text = text.lower()\n",
    "    except:\n",
    "        new_text = str(text).lower()\n",
    "    return new_text\n",
    "\n",
    "def doublespace_remove(text):\n",
    "    return re.sub(' +',' ',text)\n",
    "\n",
    "def textblobsent(text):\n",
    "    '''\n",
    "    returns the TextBlob polarity and subjectivity\n",
    "    '''\n",
    "    text = text.encode('ascii','ignore')\n",
    "    sent = TextBlob(text).sentiment\n",
    "    return pd.Series([sent.polarity,sent.subjectivity])\n",
    "\n",
    "def get_length(document):\n",
    "    return len(document)\n",
    "\n",
    "def get_num_words(document):\n",
    "    return len(document.split())\n",
    "\n",
    "def get_avg_wordlength(document):\n",
    "    wordlengths = [len(word) for word in document.split()]\n",
    "    if len(wordlengths) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return np.mean(wordlengths)\n",
    "\n",
    "def get_num_syllables(text):\n",
    "    '''\n",
    "    returns the number of syllables\n",
    "    '''\n",
    "    return textstat.syllable_count(text)\n",
    "\n",
    "def determine_tense(essay):\n",
    "    '''\n",
    "    Returns the number of past, present and future tense verbs in a given text\n",
    "    '''\n",
    "    text = word_tokenize(essay)\n",
    "    tagged = pos_tag(text)\n",
    "\n",
    "    numfuture = len([word for word in tagged if word[1] == \"MD\"])\n",
    "    numpresent = len([word for word in tagged if word[1] in [\"VBP\", \"VBZ\",\"VBG\"]])\n",
    "    numpast = len([word for word in tagged if word[1] in [\"VBD\", \"VBN\"]]) \n",
    "    \n",
    "    return pd.Series([numpast,numpresent,numfuture],index=['NumPast','NumPresent','NumFuture'])\n",
    "\n",
    "def get_pos_tags(text):\n",
    "    '''\n",
    "    Returns part of speech tag counts\n",
    "    '''\n",
    "    text = word_tokenize(text)\n",
    "    tagged = pos_tag(text)\n",
    "\n",
    "    counts = Counter([word[1] for word in tagged]).items()\n",
    "    countdict = {}\n",
    "    for key, value in counts:\n",
    "        countdict[key] = value  \n",
    "    \n",
    "    return countdict\n",
    "\n",
    "def detect_lang(text):\n",
    "    '''\n",
    "    Returns detected language\n",
    "    '''\n",
    "    text = doublespace_remove(text)\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return 'None'\n",
    "    \n",
    "def remove_stopwords(row):\n",
    "    '''\n",
    "    Multilingual stopwords removal\n",
    "    '''\n",
    "    language = row['Language']\n",
    "    if language in languages:\n",
    "        text = ' '.join([word for word in row['CleanText'].split(' ') if word not in stopwords.words(language)])\n",
    "        return text\n",
    "    else:\n",
    "        return row['CleanText']\n",
    "    \n",
    "def stem_words(row):\n",
    "    ''' \n",
    "    Multilingual word stemmer\n",
    "    '''\n",
    "    language = row['Language']    \n",
    "    if language in languages:\n",
    "        stemmer = SnowballStemmer(language)\n",
    "        text = ' '.join([stemmer.stem(word) for word in row['CleanText_NoStop'].split(' ')])\n",
    "        return text\n",
    "    else:\n",
    "        return row['CleanText_NoStop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_text(df):\n",
    "    df['Annotation Text'].fillna('',inplace=True)\n",
    "    df['CleanText'] = df['Annotation Text']\n",
    "    func_list = [perform_lowercase,punctuation_remove,doublespace_remove]\n",
    "    for func in func_list:\n",
    "        df['CleanText'] = df['CleanText'].apply(func)\n",
    "\n",
    "    return df\n",
    "\n",
    "def featurize(df):\n",
    "    \n",
    "    df['NumWords'] = df['CleanText'].apply(get_num_words)\n",
    "    df['NumCharacters'] = df['CleanText'].apply(get_length)\n",
    "    df['AvgWordLength'] = df['CleanText'].apply(get_avg_wordlength)\n",
    "    df['NumSyllables'] = df['CleanText'].apply(get_num_syllables)\n",
    "    df['language_code'] = df['CleanText'].apply(detect_lang)\n",
    "    df = df.merge(language_codes,how='left',on='language_code')\n",
    "    df['Language'] = df['Language'].astype('str')\n",
    "    df['Language'] = df['Language'].apply(lambda x: x.lower().split(';')[0])\n",
    "    df['Language'] = df['Language'].apply(lambda x: x if x in languages else 'other')\n",
    "    df['Language'].fillna('None')\n",
    "    langdummies = pd.get_dummies(df['Language'],prefix='language_')\n",
    "    \n",
    "    df['CleanText_NoStop'] = df.apply(remove_stopwords,axis=1)\n",
    "    df['CleanText_NoStop_Stemmed'] = df.apply(stem_words,axis=1)\n",
    "    df.drop(['language_code','Language'],axis=1,inplace=True)\n",
    "    \n",
    "    tenses = df['CleanText'].apply(determine_tense)\n",
    "    tenses.columns = ['tense_' + col for col in tenses.columns]\n",
    "    \n",
    "    postagcounts = []\n",
    "    for index, row in df.iterrows():\n",
    "        postagcounts.append(get_pos_tags(row['CleanText']))    \n",
    "    postagdf = pd.DataFrame(postagcounts).fillna(0)\n",
    "    postagdf.index = df.index\n",
    "    postagdf.columns = ['postag_' + col for col in postagdf.columns]\n",
    "    \n",
    "    textblobsentdf = df['CleanText'].apply(textblobsent)\n",
    "    textblobsentdf.columns = ['TextblobPolarity','TextblobSubjectivity']\n",
    "    df = pd.concat([df,textblobsentdf,tenses,postagdf,langdummies],axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "annotations = clean_text(annotations)\n",
    "annotations = featurize(annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20609, 12468)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df= .6,\n",
    "                                 min_df= .002, \n",
    "                                 stop_words=None,  \n",
    "                                 use_idf=True, \n",
    "                                 ngram_range=(1,4))\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(annotations['CleanText_NoStop_Stemmed'].values.astype('U'))\n",
    "terms = tfidf_vectorizer.get_feature_names()\n",
    "tfidf_matrix = tfidf_matrix.todense()\n",
    "tfidf = pd.DataFrame(tfidf_matrix)\n",
    "tfidf.index = annotations.index\n",
    "tfidf.columns = terms\n",
    "print tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exclude = ['Source','Category','Topic','Annotation Text','CleanText','CleanText_NoStop','CleanText_NoStop_Stemmed',\n",
    "           'OCID','PDF Page Number','Article Reference','MD','VBP','VBZ','VBG','VBD','VBN','other',\"''\"]\n",
    "features = [col for col in annotations.columns.tolist() if not col in exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = pd.concat([tfidf,annotations[features]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.fillna(0,inplace=True)\n",
    "X = X.rename(columns = {'fit':'fit_feature'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "            LogisticRegression(),\n",
    "            DecisionTreeClassifier(),\n",
    "            RandomForestClassifier(),\n",
    "            ExtraTreesClassifier()\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "        {'penalty': ['l1','l2']      # LogisticRegression\n",
    "              ,'C': [.001,.01,.1,1,10,100]\n",
    "              ,'class_weight': [None,'balanced']\n",
    "              ,'n_jobs': [-1]}\n",
    "        ,{'max_depth': [8,10,12,14]}       #DecisionTree\n",
    "        ,{'n_estimators': [100]              # RandomForest\n",
    "              ,'max_features': [.2,.33,.5] \n",
    "              ,'max_depth': [10,12,14,16] \n",
    "              ,'class_weight': ['balanced','balanced_subsample']\n",
    "              ,'n_jobs': [-1]}\n",
    "        ,{'max_features':['auto',0.2,0.33,0.5]       #ExtraTrees\n",
    "              ,'n_estimators': [100]\n",
    "              ,'n_jobs': [-1]\n",
    "              ,'max_depth': [10,12,14,16]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def grid_search(X_all, y_all, classifiers, parameters):\n",
    "    \n",
    "    # Runs grid search on given list of classifiers and parameters dictionary\n",
    "    scores = ['accuracy','precision_macro','recall_macro','roc_auc']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.33)\n",
    "    \n",
    "    # Dummy Classifier results\n",
    "    dc = DummyClassifier(strategy='most_frequent')\n",
    "    dc.fit(X_train, y_train)\n",
    "    dummy_acc_train = accuracy_score(y_train, dc.predict(X_train))\n",
    "    dummy_acc_test = accuracy_score(y_test, dc.predict(X_test))\n",
    "    print '     *** Dummy Model Accuracy ***'\n",
    "    print '     Train: ' + str(\"{0:.2f}%\".format(100*dummy_acc_train  ))\n",
    "    print '     Test: ' + str(\"{0:.2f}%\".format(100*dummy_acc_test))\n",
    "    results = []\n",
    "    for i in range(len(classifiers)):\n",
    "        model = str(classifiers[i]).split('(')[:1][0]\n",
    "        print '     ******************************************'\n",
    "        print '     *** ' + model + ' ***'        \n",
    "        print '     Tuning hyper-parameters for:' \n",
    "        for score in scores:\n",
    "            print '     ' + score.title()\n",
    "            clf = GridSearchCV(classifiers[i], parameters[i],cv=n_folds,scoring=score ,n_jobs=-1)            \n",
    "            clf.fit(X_train,y_train)\n",
    "            y_true, y_pred = y_test, clf.predict(X_test)\n",
    "            \n",
    "            acc = accuracy_score(y_true, y_pred)\n",
    "            prec = precision_score(y_true, y_pred, average='macro')\n",
    "            rec = recall_score(y_true, y_pred, average='macro')\n",
    "            roc_auc = roc_auc_score(y_true, y_pred, average='macro')\n",
    "\n",
    "            results.append([model, score, clf.best_params_, acc, prec, rec, roc_auc, dummy_acc_test])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************\n",
      "********************** Label: Stabilization **********************\n",
      "     *** Dummy Model Accuracy ***\n",
      "     Train: 98.49%\n",
      "     Test: 98.40%\n",
      "     ******************************************\n",
      "     *** LogisticRegression ***\n",
      "     Tuning hyper-parameters for:\n",
      "     Accuracy\n",
      "     Precision_Macro\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaclynweiser/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jaclynweiser/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jaclynweiser/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jaclynweiser/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/jaclynweiser/anaconda2/lib/python2.7/site-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Recall_Macro\n",
      "     Roc_Auc\n",
      "     ******************************************\n",
      "     *** DecisionTreeClassifier ***\n",
      "     Tuning hyper-parameters for:\n",
      "     Accuracy\n",
      "     Precision_Macro\n",
      "     Recall_Macro\n",
      "     Roc_Auc\n",
      "     ******************************************\n",
      "     *** RandomForestClassifier ***\n",
      "     Tuning hyper-parameters for:\n",
      "     Accuracy\n",
      "     Precision_Macro\n",
      "     Recall_Macro\n"
     ]
    }
   ],
   "source": [
    "label_results = {}\n",
    "for label in target_labels:\n",
    "    print '******************************************************************'\n",
    "    print '********************** Label: ' + label.title() + ' **********************'\n",
    "    y = labels[label]\n",
    "    label_results[label] = grid_search(X, y, classifiers, parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    resultsdf = pd.DataFrame(label_results[label])\n",
    "    resultsdf.columns = ['Model','Scoring Method','Best Params','Accuracy','PrecisionMacro','RecallMacro','AUCMacro','Dummy Accuracy']\n",
    "    print label.title()\n",
    "    display(resultsdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
