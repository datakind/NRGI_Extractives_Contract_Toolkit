{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Omidyar Extractives Project 1\n",
    "## Extract Contract Text (Notebook 7 of 8)\n",
    "### Hash-based partitition function for segmenting documents prior to clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# @file hash_partition.py\n",
    "# @author Ivan Vlahinic <ivan.newyork@gmail.com>\n",
    "def hash_partition(longstr, avgsize=16, minsize=8, maxsize=64, windowsize=16, windowslide=1):\n",
    "\n",
    "    # assert: chunk params \n",
    "    if minsize>0.25*avgsize: minsize=round(0.25*avgsize)\n",
    "    if maxsize<4.00*avgsize: maxsize=round(4.00*avgsize)\n",
    "\n",
    "    # breaks based on hash modulo \n",
    "    _ix      = [i for i in xrange(0,len(longstr)-windowsize+windowslide,windowslide)]\n",
    "    _window  = [longstr[i:min(i+windowsize,len(longstr))] for i in _ix]\n",
    "    _hash    = [hash(k) for k in _window]\n",
    "    _breaks  = [v for k,v in enumerate(_ix) if _hash[k]%avgsize==0]\n",
    "\n",
    "    # adjust for min, max chunk size\n",
    "    _breaks  = [0] + _breaks + [len(longstr)-1] # start, stop points\n",
    "    _breaks  = recursive_pop(_breaks, minsize)\n",
    "    _breaks  = recursive_insert(_breaks, maxsize) \n",
    "\n",
    "    # return chunked string\n",
    "    return [longstr[i:j] for i, j in zip(_breaks[:-1],_breaks[1:])]\n",
    "\n",
    "def recursive_pop(_breaks, minsize):\n",
    "    _ix_min = [k for k,_ in enumerate(xrange(len(_breaks)-1)) if _breaks[k+1]-_breaks[k] < minsize]\n",
    "    if _ix_min:\n",
    "        for k,ix in enumerate(_ix_min):\n",
    "            _breaks.pop(ix-k+1)\n",
    "    return _breaks\n",
    "\n",
    "def recursive_insert(_breaks, maxsize):\n",
    "    _ix_max = [k for k,_ in enumerate(xrange(len(_breaks)-1)) if _breaks[k+1]-_breaks[k] > maxsize]\n",
    "    if _ix_max: # non-empty list\n",
    "        for ix,k in enumerate(_ix_max):\n",
    "            _breaks.insert(k+ix+1,_breaks[k+ix]+maxsize)\n",
    "        _breaks = recursive_insert(_breaks, maxsize)\n",
    "    return _breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## document 1\n",
    "longstr1 = \\\n",
    "\"Membership of the Union of Soviet Socialist Republics in the United Nations, \\\n",
    "including the Security Council and all other organs and organizations of the United Nations system, \\\n",
    "is being continued by the Russian Federation (RSFSR) with the support of the countries of the Commonwealth of \\\n",
    "Independent States. In this connection, I request that the name 'Russian Federation' should be used in the United \\\n",
    "Nations in place of the name 'the Union of Soviet Socialist Republics'. The Russian Federation maintains full \\\n",
    "responsibility for all the rights and obligations of the USSR under the Charter of the United Nations, including \\\n",
    "the financial obligations. I request that you consider this letter as confirmation of the credentials to represent \\\n",
    "the Russian Federation in United Nations organs for all the persons currently holding the credentials of representatives \\\n",
    "of the USSR to the United Nations.\"\n",
    "\n",
    "## document 2: minor changes inserted into document 1\n",
    "longstr2 = \\\n",
    "\"Membership of the Union of Soviet Socialist Republics in the United Nations, \\\n",
    "including the Security Council and all other organs and organizations of the United Nations system, \\\n",
    "is being continued by the Russian Federation (RSFSR) with the support of the countries of the Commonwealth of \\\n",
    "Independent States. In this connection, I request that the name 'Russian Federation' should be used in the United \\\n",
    "Nations in place of the name 'the ---XXX--- Union of Soviet Socialist Republics'. The Russian Federation maintains full \\\n",
    "responsibility for all the rights ---|||--- and obligations of the USSR under the Charter of the United Nations, including \\\n",
    "the financial obligations. I request that you consider this letter as confirmation of the credentials to represent \\\n",
    "the Russian Federation in United ---ZZZ--- Nations organs for all the persons currently holding the credentials of representatives \\\n",
    "of the USSR to the United Nations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXAMPLE USE CASE: DOCUMENT SIMILARITY\n",
      "\n",
      "\n",
      "Percent similarity between document 1 and 2: \n",
      "0.898\n",
      "\n",
      "Common elements between documents 1 and 2:\n",
      "['Membership of the Union', ' of Soviet Social', 'ist Republics in the United Nations', ', inclu', 'ding the Security Council and all other or', 'gans an', 'd organizations of the United Nat', 'ions system', ', is', ' being continued by the Russia', 'n Federati', 'on (RSFSR)', ' with the sup', 'port of the countries of th', 'e Commonw', 'ealth of ', 'Indepen', 'dent States. In ', 'this ', 'connection, I request that the ', \"name 'Russi\", 'an Fed', 'erat', \"ion' should be used in the \", 'Unit', 'ed Nation', 's in', ' place o', ' of Soviet Socia', 'list Repu', \"blics'. The Russian Federation maintains full responsibility for\", ' and obligations o', 'f the', ' USSR under the Charter of the United Nations', ', including the financial obligations. I request that you consid', 'er this let', 'ter as confirmati', 'on of the credent', 'tions or', 'gans f', 'or all th', 'e persons currentl', 'y holding the credentials of repr', 'esentatives of the USSR to the United Nations']\n",
      "\n",
      "Elements not in common between document 1 and 2:\n",
      "[\"f the name 'the Union\", ' ', 'all the rights', 'ials to represent the Russian Federation in Unit', 'ed Na']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = set(hash_partition(longstr1))\n",
    "b = set(hash_partition(longstr2))\n",
    "\n",
    "print \n",
    "print \"EXAMPLE USE CASE: DOCUMENT SIMILARITY\"\n",
    "print \n",
    "\n",
    "print \n",
    "print \"Percent similarity between document 1 and 2: \\n%0.3f\"%( len(a&b)/float(min(len(a),len(b))) )\n",
    "\n",
    "print \n",
    "print \"Common elements between documents 1 and 2:\"\n",
    "print [k for k in hash_partition(longstr1) if k in hash_partition(longstr2)]\n",
    "\n",
    "print \n",
    "print \"Elements not in common between document 1 and 2:\"\n",
    "print [k for k in hash_partition(longstr1) if k not in hash_partition(longstr2)]\n",
    "print "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### REFERENCE CODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary functions\n",
    "char_to_remove = set([' ','*',',',';',':','-','_','[',']',']','&','`','@','*','^','|','~','\\'','\\\"'])\n",
    "def doc_clean(longstr):\n",
    "    longstr= re.sub(r'[\\x00-x08\\x0b\\x0c\\x0e-\\xlf\\x7f-\\xff]', '', longstr) #remove all non-printable characters\n",
    "    longstr = ''.join(i for i in longstr if i not in char_to_remove and ord(i) < 128).replace('\\r','').replace('\\n','').replace('\\t','')\n",
    "    return longstr\n",
    "def partision(longstr, chunksize, hashflag=True):\n",
    "    if hashflag:\n",
    "        return [hashlib.shal(longstr[i:j]).hexdigest() for i, j in zip(list(np.cumsum([0]+chunksize[:-1])),list(np.cumsum(chunksize)))]\n",
    "    else:\n",
    "        return [longstr[i:j] for i, j in zip(list(np.cumsum([0]+chunksize[:-1])), list (np.cumsum(chunksize)))]\n",
    "\n",
    "#clustering based on connected components\n",
    "def find_cluster_cutoff(G, cutoff=.9, minCluster=0):\n",
    "    print '\\nSimilarity cutoff: %f' % cutoff\n",
    "    H = G.copy()\n",
    "    H.revmove_edges_from([(u,v) for (u,v,s) in H.edges(data=True) if d['weight'] < cutoff])\n",
    "    clusters = [sorted(i) for i in sorted(nx.connected_components(H), key=len,reverse=True) if len(i)>minCluster]\n",
    "    return clusters\n",
    "\n",
    "def find_cluster_louvan(G,minCluster=0):\n",
    "    partition = cm.best_partition(G)\n",
    "    clusters = []\n",
    "    for label in set(partition.values()):\n",
    "        clusters = []\n",
    "        for label in set(partition.values()):\n",
    "            clusters.append([i for i in partiion.keys() if partiion[i] == label])\n",
    "        clusters = [sorted(i) for i in sorted(clusters, key = len, reverse=True) if len(i)>minCluster]\n",
    "    return clusters\n",
    "\n",
    "def print_cluster_summary(G,clusters):\n",
    "    print '\\nNumber of clusters identified: %d' % len(clusters)\n",
    "    print 'Document coverage: %d%% (%d of %d)' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "fpraw = 'docFingerprints'\n",
    "fpsorted = 'docFingerprints_sorted'\n",
    "# generate file fingerprints\n",
    "# initialize graph nodes, one per document\n",
    "# 1. scrub of non-ascii characters and remove all spaces\n",
    "# 2. identify file markers via 'rabin fingerprint'\n",
    "# 3. break up file marker-2-marker and sort by docFingerprint\n",
    "G = nx.Graph()\n",
    "with open(fpraw, 'w') as fp:\n",
    "    for k, filepath in enumerate(filePaths):\n",
    "        a = doc_clean(open(filepath).read()) # clean up document\n",
    "        b = rabin_chunks(a) # identify chunks per rabin fingerprint algorithm\n",
    "        c = set(partition(a,b,hashflag=False)) # partition document into its fingerprints and hash (optional)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
